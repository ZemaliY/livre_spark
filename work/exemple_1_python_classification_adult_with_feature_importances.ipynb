{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python\n",
    "## modules\n",
    "import time  \n",
    "import sys  \n",
    "import numpy as np \n",
    "import copy\n",
    "## fonctions\n",
    "from datetime                  import datetime\n",
    "from dateutil.relativedelta    import relativedelta\n",
    "\n",
    "# Spark 2.0\n",
    "from pyspark.sql               import SparkSession \n",
    "\n",
    "# Fonctions\n",
    "from pyspark.sql               import Row\n",
    "from pyspark.sql.types         import *\n",
    "\n",
    "# Machine learning\n",
    "from pyspark.ml                import Pipeline\n",
    "from pyspark.ml.feature        import OneHotEncoder\n",
    "from pyspark.ml.feature        import StringIndexer\n",
    "from pyspark.ml.feature        import VectorIndexer\n",
    "from pyspark.ml.feature        import VectorAssembler\n",
    "from pyspark.ml.evaluation     import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Ancienne librairie de ML\n",
    "from pyspark.mllib.evaluation  import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_name    = \"classification_sexe_cycliste_2\"\n",
    "nb_cores    = 3\n",
    "paralelisme = 3\n",
    "memory      = 3\n",
    "start_load  = time.time()\n",
    "\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    ".config(\"spark.app.name\"                  , app_name                                   )\\\n",
    ".config(\"spark.cores.max\"                 , \"%s\"%(nb_cores)                            )\\\n",
    ".config(\"spark.mesos.coarse\"             , \"True\"                                      )\\\n",
    ".config(\"spark.executor.memory\"          , \"%sg\"%memory                                )\\\n",
    ".config(\"spark.driver.memory\"            , \"%sg\"%memory                                )\\\n",
    ".config(\"spark.serializer\"               , \"org.apache.spark.serializer.KryoSerializer\")\\\n",
    ".config(\"spark.kryoserializer.buffer.max\", \"1024m\"                                     )\\\n",
    ".config(\"spark.driver.maxResultSize\"     , \"10g\"                                       )\\\n",
    ".config(\"spark.cores.max\"                , \"%s\"%(nb_cores)                             )\\\n",
    ".config(\"spark.default.parallelism\"      , \"%s\"%(nb_cores*paralelisme)                 )\\\n",
    ".config(\"spark.storage.memoryFraction\"   , \"0.5\"                                       )\\\n",
    ".getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://861ebdbd2c1e:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>classification_sexe_cycliste_2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fece78a2d30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Structure et import du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any parent up to mount point /home/jovyan)\r\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\r\n"
     ]
    }
   ],
   "source": [
    "!git status \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_fichier = \"./../data/Villes/ville_1.csv\"\n",
    "data = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(url_fichier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1083"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- home: string (nullable = true)\n",
      " |-- travail: string (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- statut: string (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) one hot encoding sur le sexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import IndexToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding = StringIndexer(inputCol=\"sexe\", outputCol=\"sexe-num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_one_hot_encoding = one_hot_encoding.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_avec_sexe_en_binaire = model_one_hot_encoding.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=5251, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:26.60 lat:28.13)', travail='(lon:21.08 lat:14.11)', sportif=False, casseur=False, statut='reserviste', salaire=29800.610034665042, sexe='F', age=18, sportivite=0.1, velo_perf_minimale=0.4, sexe-num=1.0),\n",
       " Row(id=5252, vitesse_a_pied=0.14974625830876215, vitesse_a_velo=0.37436564577190534, home='(lon:0.26 lat:42.61)', travail='(lon:36.35 lat:33.28)', sportif=False, casseur=False, statut='professeur', salaire=23595.44383981423, sexe='F', age=28, sportivite=0.7487312915438107, velo_perf_minimale=0.4, sexe-num=1.0),\n",
       " Row(id=5253, vitesse_a_pied=0.6309711587089704, vitesse_a_velo=1.6825897565572543, home='(lon:3.34 lat:13.95)', travail='(lon:24.75 lat:48.15)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=18530.14776280135, sexe='H', age=65, sportivite=2.103237195696568, velo_perf_minimale=0.4, sexe-num=0.0),\n",
       " Row(id=5254, vitesse_a_pied=0.04009596300649916, vitesse_a_velo=0.10692256801733109, home='(lon:19.54 lat:43.69)', travail='(lon:38.57 lat:42.65)', sportif=False, casseur=False, statut='technicien_de_surface', salaire=18997.60281005325, sexe='H', age=26, sportivite=0.13365321002166386, velo_perf_minimale=0.4, sexe-num=0.0),\n",
       " Row(id=5255, vitesse_a_pied=0.02, vitesse_a_velo=0.05, home='(lon:28.51 lat:41.70)', travail='(lon:17.67 lat:25.16)', sportif=False, casseur=False, statut='éboueur', salaire=23618.479750220806, sexe='F', age=50, sportivite=0.1, velo_perf_minimale=0.4, sexe-num=1.0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_avec_sexe_en_binaire.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) création d'une colonne \"features\" qui comprend les paramètres explicatifs du sexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'vitesse_a_pied',\n",
       " 'vitesse_a_velo',\n",
       " 'home',\n",
       " 'travail',\n",
       " 'sportif',\n",
       " 'casseur',\n",
       " 'statut',\n",
       " 'salaire',\n",
       " 'sexe',\n",
       " 'age',\n",
       " 'sportivite',\n",
       " 'velo_perf_minimale',\n",
       " 'sexe-num']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colonnes = data_avec_sexe_en_binaire.columns\n",
    "colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'casseur',\n",
       " 'home',\n",
       " 'salaire',\n",
       " 'sportif',\n",
       " 'sportivite',\n",
       " 'statut',\n",
       " 'travail',\n",
       " 'velo_perf_minimale',\n",
       " 'vitesse_a_pied',\n",
       " 'vitesse_a_velo']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colonnes_a_enlever = ['sexe', 'sexe-num', 'id']\n",
    "colonnes_sans_y = [x for x in colonnes if x not in colonnes_a_enlever]\n",
    "sorted(colonnes_sans_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'casseur',\n",
       " 'home',\n",
       " 'salaire',\n",
       " 'sportif',\n",
       " 'sportivite',\n",
       " 'statut',\n",
       " 'travail',\n",
       " 'velo_perf_minimale',\n",
       " 'vitesse_a_pied',\n",
       " 'vitesse_a_velo']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colonnes_a_garder = list(set(colonnes) - set(colonnes_a_enlever))\n",
    "sorted(colonnes_a_garder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) gestion des  colonnes catégorielles / numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexStringColumns(df, cols):\n",
    "    \"\"\"\n",
    "    Convertit les colonnes de string en numériques.\n",
    "    (pbm = donne l'idée d'un ordre naturel)\n",
    "    Parameters:\n",
    "        df : matrice à modifier \n",
    "            dataframe\n",
    "        cols : noms des colonnes à indexer\n",
    "            list de chaine de caractère\n",
    "            \n",
    "    Return: dataframe\n",
    "    \"\"\"\n",
    "    from pyspark.ml.feature import StringIndexer\n",
    "    from collections import OrderedDict\n",
    "    newdf = df\n",
    "    string_indexers = OrderedDict()\n",
    "    for old_col in cols:\n",
    "        \n",
    "        new_col = old_col+\"-num\"\n",
    "        indexer = StringIndexer(inputCol=old_col, outputCol=new_col)\n",
    "        \n",
    "        model   = indexer.fit(newdf)\n",
    "        newdf   = model.transform(newdf)\n",
    "        newdf   = newdf.drop(old_col)\n",
    "        newdf   = newdf.withColumnRenamed(new_col, old_col)\n",
    "        string_indexers[old_col] = model\n",
    "    return newdf, string_indexers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncodeColumns(df, cols):\n",
    "    \"\"\"\n",
    "    Convertit une colonne contenant n modalité \n",
    "    en n colonne ne comprenant qu'une seule valeur.\n",
    "    (Supprime les effets d'ordre des valeurs numériques)\n",
    "    Parameters:\n",
    "        df : matrice à modifier \n",
    "            dataframe\n",
    "        cols : noms des colonnes à indexer\n",
    "            list de chaine de caractère\n",
    "            \n",
    "    Return: dataframe\n",
    "    \"\"\"\n",
    "    from pyspark.ml.feature import OneHotEncoder\n",
    "    from collections import OrderedDict\n",
    "    newdf = df\n",
    "    one_hot_encoders = OrderedDict()\n",
    "    for old_col in cols:\n",
    "        new_col   = old_col+\"-onehot\"\n",
    "        onehotenc = OneHotEncoder(inputCol=old_col, outputCol=new_col, dropLast=False)\n",
    "        newdf     = onehotenc.transform(newdf)\n",
    "        newdf     = newdf.drop(old_col)\n",
    "        newdf     = newdf.withColumnRenamed(new_col, old_col)\n",
    "        one_hot_encoders[old_col] = onehotenc\n",
    "    return newdf, one_hot_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1) catégories => numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "colY     = \"sexe\"\n",
    "colY_num = \"sexe-num\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['home', 'travail', 'statut', 'sexe']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeString = [x[0] for x in data.dtypes if x[1]=='string']\n",
    "typeString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['home', 'travail', 'statut']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colString_without_Y = copy.copy(typeString)\n",
    "colString_without_Y.remove(colY)\n",
    "colString_without_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- home: string (nullable = true)\n",
      " |-- travail: string (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- statut: string (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      " |-- sexe-num: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_avec_sexe_en_binaire.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      " |-- sexe-num: double (nullable = false)\n",
      " |-- home: double (nullable = false)\n",
      " |-- travail: double (nullable = false)\n",
      " |-- statut: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2, dico_indexers = indexStringColumns(data_avec_sexe_en_binaire, colString_without_Y)\n",
    "data2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2) numériques => one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['home', 'travail', 'statut']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colString_without_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=5251, vitesse_a_pied=0.02, vitesse_a_velo=0.05, sportif=False, casseur=False, salaire=29800.610034665042, sexe='F', age=18, sportivite=0.1, velo_perf_minimale=0.4, sexe-num=1.0, home=SparseVector(1083, {818: 1.0}), travail=SparseVector(1083, {728: 1.0}), statut=SparseVector(6, {5: 1.0}))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3, dico_encoders = oneHotEncodeColumns(data2, colString_without_Y)\n",
    "data3.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- vitesse_a_pied: double (nullable = true)\n",
      " |-- vitesse_a_velo: double (nullable = true)\n",
      " |-- sportif: boolean (nullable = true)\n",
      " |-- casseur: boolean (nullable = true)\n",
      " |-- salaire: double (nullable = true)\n",
      " |-- sexe: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- sportivite: double (nullable = true)\n",
      " |-- velo_perf_minimale: double (nullable = true)\n",
      " |-- sexe-num: double (nullable = false)\n",
      " |-- home: vector (nullable = true)\n",
      " |-- travail: vector (nullable = true)\n",
      " |-- statut: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data3.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3) plusieurs colonnes => un vecteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'vitesse_a_pied',\n",
       " 'vitesse_a_velo',\n",
       " 'sportif',\n",
       " 'casseur',\n",
       " 'salaire',\n",
       " 'sexe',\n",
       " 'age',\n",
       " 'sportivite',\n",
       " 'velo_perf_minimale',\n",
       " 'sexe-num',\n",
       " 'home',\n",
       " 'travail',\n",
       " 'statut']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sexe-num'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colY_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'vitesse_a_pied',\n",
       " 'vitesse_a_velo',\n",
       " 'sportif',\n",
       " 'casseur',\n",
       " 'salaire',\n",
       " 'sexe',\n",
       " 'age',\n",
       " 'sportivite',\n",
       " 'velo_perf_minimale',\n",
       " 'sexe-num',\n",
       " 'home',\n",
       " 'travail',\n",
       " 'statut']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'vitesse_a_pied', 'vitesse_a_velo', 'sportif', 'casseur', 'salaire', 'age', 'sportivite', 'velo_perf_minimale', 'statut']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(id=5251, vitesse_a_pied=0.02, vitesse_a_velo=0.05, sportif=False, casseur=False, salaire=29800.610034665042, sexe='F', age=18, sportivite=0.1, velo_perf_minimale=0.4, sexe-num=1.0, home=SparseVector(1083, {818: 1.0}), travail=SparseVector(1083, {728: 1.0}), statut=SparseVector(6, {5: 1.0}), features=SparseVector(15, {0: 5251.0, 1: 0.02, 2: 0.05, 5: 29800.61, 6: 18.0, 7: 0.1, 8: 0.4, 14: 1.0})),\n",
       " Row(id=5252, vitesse_a_pied=0.14974625830876215, vitesse_a_velo=0.37436564577190534, sportif=False, casseur=False, salaire=23595.44383981423, sexe='F', age=28, sportivite=0.7487312915438107, velo_perf_minimale=0.4, sexe-num=1.0, home=SparseVector(1083, {991: 1.0}), travail=SparseVector(1083, {38: 1.0}), statut=SparseVector(6, {4: 1.0}), features=SparseVector(15, {0: 5252.0, 1: 0.1497, 2: 0.3744, 5: 23595.4438, 6: 28.0, 7: 0.7487, 8: 0.4, 13: 1.0}))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choix des colonnes\n",
    "features = data3.columns\n",
    "\n",
    "# on supprime les colonnes dont toutes les valeurs sont différentes\n",
    "features.remove(\"home\")\n",
    "features.remove(\"travail\")\n",
    "\n",
    "features.remove(colY)\n",
    "features.remove(colY_num)\n",
    "# Assembleur\n",
    "print(features)\n",
    "assemblor = VectorAssembler(inputCols=features, outputCol=\"features\", )\n",
    "# Application\n",
    "data4 = assemblor.transform(data3)\n",
    "data4.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'id',\n",
       " 1: 'vitesse_a_pied',\n",
       " 2: 'vitesse_a_velo',\n",
       " 3: 'sportif',\n",
       " 4: 'casseur',\n",
       " 5: 'salaire',\n",
       " 6: 'age',\n",
       " 7: 'sportivite',\n",
       " 8: 'velo_perf_minimale',\n",
       " 9: 'cadre',\n",
       " 10: 'employe',\n",
       " 11: 'technicien_de_surface',\n",
       " 12: 'éboueur',\n",
       " 13: 'professeur',\n",
       " 14: 'reserviste'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nom_des_features = []\n",
    "for col in assemblor.getInputCols():\n",
    "    if col in dico_indexers.keys():\n",
    "        nom_des_features.extend(dico_indexers[col].labels)\n",
    "    else:\n",
    "        nom_des_features.append(col)\n",
    "indices_et_noms_des_features = {indice: col for indice, col in enumerate(nom_des_features)}\n",
    "indices_et_noms_des_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4) projection, et cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(features,VectorUDT,true),StructField(sexe-num,DoubleType,false)))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data5 = data4.select(\"features\", colY_num)\n",
    "data5.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1083"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data6 = data5.dropDuplicates()\n",
    "data6.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) création d'un vecteur avec les colonnes à garder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from pyspark.ml.feature import VectorAssembler\n",
    "    instance = VectorAssembler(inputCols=colonnes_a_garder, outputCol=\"features\")\n",
    "    data_avec_col_features = instance.transform()\n",
    "    data_avec_col_features.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5) équilibrage des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|sexe-num|count|\n",
      "+--------+-----+\n",
      "|     0.0|  560|\n",
      "|     1.0|  523|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data6.groupBy(colY_num).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    nb_examples = 10000\n",
    "    income_0             = data6.filter(\"income == 0\")\n",
    "    _10000_income_0      = income_0.sample(False, nb_examples/float(income_0.count()))\n",
    "\n",
    "    income_1             = data6.filter(\"income == 1\")\n",
    "    _10000_income_1      = income_1.sample(False, nb_examples/float(income_1.count()))\n",
    "\n",
    "    classes_equilibrees  = _10000_income_0.union(_10000_income_1)\n",
    "    print (_10000_income_0.count(), _10000_income_1.count(), classes_equilibrees.count())\n",
    "else:\n",
    "    classes_equilibrees = data6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- sexe-num: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data6.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=SparseVector(15, {0: 5558.0, 1: 1.2136, 2: 3.034, 5: 21831.9187, 6: 74.0, 7: 6.068, 8: 0.4, 13: 1.0}), sexe-num=1.0)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_equilibrees.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- sexe-num: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes_equilibrees.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division en jeu de test, et jeu d'apprentissage\n",
    "(trainingData, testData) = classes_equilibrees.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features', 'sexe-num']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf          = RandomForestClassifier(labelCol=colY_num)\n",
    "model       = rf.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(  labelCol      = colY_num , \n",
    "                                                predictionCol = \"prediction\"   , \n",
    "                                                metricName    = \"accuracy\"     )\n",
    "accuracy  = evaluator.evaluate(predictions)\n",
    "error     = 1 - accuracy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest => Accuracy = 0.765957, Error = 0.23404255319148937\n"
     ]
    }
   ],
   "source": [
    "print(\"RandomForest => Accuracy = %g, Error = %s\" % (accuracy, error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_les_plus_importantes =model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = []\n",
    "for indice, valeur in enumerate(variables_les_plus_importantes.toArray()):\n",
    "    r.append({\"colonne\" : indices_et_noms_des_features[indice]  ,\n",
    "              \"valeur\"  : valeur                                })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colonne</th>\n",
       "      <th>valeur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vitesse_a_pied</td>\n",
       "      <td>0.372791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vitesse_a_velo</td>\n",
       "      <td>0.279452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sportivite</td>\n",
       "      <td>0.152970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>salaire</td>\n",
       "      <td>0.117894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>0.024709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age</td>\n",
       "      <td>0.023695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>technicien_de_surface</td>\n",
       "      <td>0.006143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cadre</td>\n",
       "      <td>0.006023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>employe</td>\n",
       "      <td>0.004271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>professeur</td>\n",
       "      <td>0.003473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sportif</td>\n",
       "      <td>0.002325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>éboueur</td>\n",
       "      <td>0.002154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>velo_perf_minimale</td>\n",
       "      <td>0.002133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>reserviste</td>\n",
       "      <td>0.001962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>casseur</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  colonne    valeur\n",
       "1          vitesse_a_pied  0.372791\n",
       "2          vitesse_a_velo  0.279452\n",
       "7              sportivite  0.152970\n",
       "5                 salaire  0.117894\n",
       "0                      id  0.024709\n",
       "6                     age  0.023695\n",
       "11  technicien_de_surface  0.006143\n",
       "9                   cadre  0.006023\n",
       "10                employe  0.004271\n",
       "13             professeur  0.003473\n",
       "3                 sportif  0.002325\n",
       "12                éboueur  0.002154\n",
       "8      velo_perf_minimale  0.002133\n",
       "14             reserviste  0.001962\n",
       "4                 casseur  0.000005"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(r)\n",
    "df.sort_values(\"valeur\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "    newdf       = copy.copy(data)\n",
    "    inputCol_1  = newdf.columns[1]\n",
    "    outputCol_1 = col+\"-num\"\n",
    "    indexer     = StringIndexer(inputCol=inputCol_1, outputCol=outputCol_1)\n",
    "    model       = indexer.fit(newdf)\n",
    "    newdf_1     = model.transform(newdf)\n",
    "    newdf_1.select(inputCol_1, outputCol_1).dropDuplicates().show()\n",
    "\n",
    "    inputCol_2   = outputCol_1\n",
    "    outputCol_2  = col+\"-onehot\"\n",
    "    onehotenc    = OneHotEncoder(inputCol=inputCol_2, outputCol=outputCol_2, dropLast=False)\n",
    "    newdf_2      = onehotenc.transform(newdf_1)\n",
    "    newdf_2.select(inputCol_1, outputCol_1, outputCol_2).dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1) variation du nombre d'arbres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 arbre => Accuracy = 1, Error = 0.0\n",
      "6 arbre => Accuracy = 0.764706, Error = 0.23529411764705888\n",
      "11 arbre => Accuracy = 0.764706, Error = 0.23529411764705888\n",
      "16 arbre => Accuracy = 1, Error = 0.0\n"
     ]
    }
   ],
   "source": [
    "nb_max_arbre = 20\n",
    "for ntree in range(1,nb_max_arbre, 5) :\n",
    "    rf          = RandomForestClassifier(labelCol=colY_num, numTrees=ntree)\n",
    "    model       = rf.fit(trainingData)\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(  labelCol      = colY_num , \n",
    "                                                    predictionCol = \"prediction\"   , \n",
    "                                                    metricName    = \"accuracy\"     )\n",
    "    accuracy  = evaluator.evaluate(predictions)\n",
    "    error     = 1 - accuracy\n",
    "\n",
    "    print(\"%s arbre => Accuracy = %g, Error = %s\" % (ntree, accuracy, error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.isLargerBetter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2) variation de la profondeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 arbre, depth = 5 => Error = 0\n",
      "1 arbre, depth = 10 => Error = 0\n",
      "1 arbre, depth = 20 => Error = 0\n",
      "10 arbre, depth = 5 => Error = 0.235294\n",
      "10 arbre, depth = 10 => Error = 0.235294\n",
      "10 arbre, depth = 20 => Error = 0.235294\n",
      "20 arbre, depth = 5 => Error = 0\n",
      "20 arbre, depth = 10 => Error = 0\n",
      "20 arbre, depth = 20 => Error = 0\n"
     ]
    }
   ],
   "source": [
    "test_forets = [1, 10, 20]\n",
    "test_depth  = [5, 10, 20]\n",
    "for ntree in test_forets:\n",
    "    for depth in test_depth:\n",
    "        rf          = RandomForestClassifier(labelCol=colY_num, numTrees=ntree, maxDepth=depth)\n",
    "        model       = rf.fit(trainingData)\n",
    "        predictions = model.transform(testData)\n",
    "\n",
    "        evaluator = MulticlassClassificationEvaluator(  labelCol      = colY_num , \n",
    "                                                        predictionCol = \"prediction\"   , \n",
    "                                                        metricName    = \"accuracy\"     )\n",
    "        accuracy  = 1 - evaluator.evaluate(predictions)\n",
    "\n",
    "        print(\"%s arbre, depth = %s => Error = %g\" % (ntree, depth, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time as now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3) Etendue de la forêt\n",
    "(on peut aller prendre un café)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 arbre, depth = 30 => Error = 0.0, duree = 43.1983597278595 sec \n",
      "30 arbre, depth = 30 => Error = 0.0, duree = 75.95458912849426 sec \n",
      "50 arbre, depth = 30 => Error = 0.0, duree = 110.35692596435547 sec \n"
     ]
    }
   ],
   "source": [
    "test_forets = [ 20, 30,  50]\n",
    "test_depth  = [ 30] # limite à 30 de profondeurs \n",
    "for ntree in test_forets:\n",
    "    for depth in test_depth:\n",
    "        debut       = now()\n",
    "        # modélisation :\n",
    "        rf          = RandomForestClassifier(labelCol=colY_num, numTrees=ntree, maxDepth=depth,)\n",
    "        model       = rf.fit(trainingData)\n",
    "        predictions = model.transform(testData)\n",
    "        # mesure de la performance :\n",
    "        evaluator   = MulticlassClassificationEvaluator(  labelCol      = colY_num , \n",
    "                                                          predictionCol = \"prediction\"   , \n",
    "                                                          metricName    = \"accuracy\"     )\n",
    "        accuracy     = 1 - evaluator.evaluate(predictions)\n",
    "        duree        = now()-debut\n",
    "        print(\"{0} arbre, depth = {1} => Error = {2:3.4}, duree = {3:5} sec \".format (ntree, depth, accuracy, duree))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tentative de récupération des features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "    newdf       = copy.copy(data)\n",
    "    inputCol_1  = newdf.columns[1]\n",
    "    outputCol_1 = col+\"-num\"\n",
    "    indexer     = StringIndexer(inputCol=inputCol_1, outputCol=outputCol_1)\n",
    "    model       = indexer.fit(newdf)\n",
    "    newdf_1     = model.transform(newdf)\n",
    "    newdf_1.select(inputCol_1, outputCol_1).dropDuplicates().show()\n",
    "\n",
    "    inputCol_2   = outputCol_1\n",
    "    outputCol_2  = col+\"-onehot\"\n",
    "    onehotenc    = OneHotEncoder(inputCol=inputCol_2, outputCol=outputCol_2, dropLast=False)\n",
    "    newdf_2      = onehotenc.transform(newdf_1)\n",
    "    newdf_2.select(inputCol_1, outputCol_1, outputCol_2).dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) changement des classifieurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes           => Accuracy = 0.412, Error = 0.588, duree =  2.78 sec\n",
      "GBTClassifier        => Accuracy =  1.0, Error =  0.0, duree = 1.08e+02 sec\n",
      "LogisticRegression   => Accuracy =  1.0, Error =  0.0, duree =  50.0 sec\n",
      "best_classifier = GBTClassifier, best_accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "classifiers = { \"NaiveBayes\"         : NaiveBayes(labelCol=colY_num)         , \n",
    "                \"GBTClassifier\"      : GBTClassifier(labelCol=colY_num)      , \n",
    "                \"LogisticRegression\" : LogisticRegression(labelCol=colY_num) }\n",
    "best_accuracy   = 0\n",
    "best_classifier = \"\"\n",
    "for classifierName,classifier in classifiers.items():\n",
    "    debut       = now()\n",
    "    model       = classifier.fit(trainingData)\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    evaluator   = MulticlassClassificationEvaluator(  labelCol      = colY_num , \n",
    "                                                      predictionCol = \"prediction\"   , \n",
    "                                                      metricName    = \"accuracy\"     )\n",
    "    accuracy    = evaluator.evaluate(predictions)\n",
    "    error       = 1 - accuracy\n",
    "    duree       = now() - debut\n",
    "    print(\"{0:20} => Accuracy = {1:4.3}, Error = {2:4.3}, duree = {3:5.3} sec\".format (classifierName ,  \n",
    "                                                                                       accuracy       , \n",
    "                                                                                       error          , \n",
    "                                                                                       duree         ))\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy   = accuracy\n",
    "        best_classifier = classifierName\n",
    "        \n",
    "print (\"best_classifier = %s, best_accuracy = %s\"%(best_classifier, best_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_classifier = GBTClassifier, best_accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "print (\"best_classifier = %s, best_accuracy = %s\"%(best_classifier, best_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
