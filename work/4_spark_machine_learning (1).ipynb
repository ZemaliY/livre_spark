{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark ML : la librairie de machine learning de Spark\n",
    "La librairie Spark pour le machine learning s’appelle *ml* . \n",
    "Elle comprend différents modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import clustering\n",
    "from pyspark.ml import classification\n",
    "from pyspark.ml import regression\n",
    "from pyspark.ml import stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introspecter les objets\n",
    "On peut profiter du mot clef *__dict__* pour trouver les objets contenus dans chacun de ces modules, et filtrer sur des mots clefs.\n",
    "Le module de Stat propose certains tests :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChiSquareTest', 'KolmogorovSmirnovTest']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in stat.__dict__.keys() if \"Test\" in k ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module de clutering quelques algorithmes  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JavaPredictionModel',\n",
       " 'JavaModel',\n",
       " 'HasCollectSubModels',\n",
       " 'GaussianMixtureModel',\n",
       " 'KMeansModel',\n",
       " 'BisectingKMeansModel',\n",
       " 'LDAModel',\n",
       " 'DistributedLDAModel',\n",
       " 'LocalLDAModel']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in clustering.__dict__.keys() if \"Model\" in k ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les modules de classification d'autres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TreeClassifierParams',\n",
       " 'DecisionTreeClassifier',\n",
       " 'RandomForestClassifier',\n",
       " 'GBTClassifier',\n",
       " 'MultilayerPerceptronClassifier']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in classification.__dict__.keys() if \"Classifier\" in k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a plus de modules de régression : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LinearRegression',\n",
       " 'LinearRegressionModel',\n",
       " 'LinearRegressionSummary',\n",
       " 'LinearRegressionTrainingSummary',\n",
       " 'IsotonicRegression',\n",
       " 'IsotonicRegressionModel',\n",
       " 'DecisionTreeRegressionModel',\n",
       " 'RandomForestRegressionModel',\n",
       " 'GBTRegressionModel',\n",
       " 'AFTSurvivalRegression',\n",
       " 'AFTSurvivalRegressionModel',\n",
       " 'GeneralizedLinearRegression',\n",
       " 'GeneralizedLinearRegressionModel',\n",
       " 'GeneralizedLinearRegressionSummary',\n",
       " 'GeneralizedLinearRegressionTrainingSummary']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in regression.__dict__.keys() if \"Regression\" in k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autour des algorithmes,des outils pour passer à l'échelle\n",
    "Les algorithmes classiques doivent être adaptés pour : \n",
    "1. Préciser les types pour être convertis de Python vers Scala\n",
    "2. Être distribués sur tout le cluster\n",
    "3. Transformer les données en chiffre\n",
    "\n",
    "Spark propose plusieurs classes pour nous aider dans ces tâches : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml import Estimator\n",
    "from pyspark.ml import param\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous savons faire nous pouvons introspecter ces modules pour imaginer ce qu'ils contiennent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer ['transform']\n",
      "Estimator ['fitMultiple', 'fit']\n",
      "param ['array', 'sys', 'basestring', 'xrange', 'unicode', 'ABCMeta', 'copy', 'np', 'JavaObject', 'DenseVector', 'Vector', 'Matrix', 'Identifiable', 'Param', 'TypeConverters', 'Params', 'shared']\n",
      "Pipeline ['stages', 'setStages', 'getStages', 'setParams', 'copy', 'write', 'read']\n",
      "evaluation ['sys', 'abstractmethod', 'ABCMeta', 'since', 'JavaParams', 'Param', 'Params', 'TypeConverters', 'HasLabelCol', 'HasPredictionCol', 'HasRawPredictionCol', 'HasFeaturesCol', 'JavaMLReadable', 'JavaMLWritable', 'Evaluator', 'JavaEvaluator', 'BinaryClassificationEvaluator', 'RegressionEvaluator', 'MulticlassClassificationEvaluator', 'ClusteringEvaluator']\n"
     ]
    }
   ],
   "source": [
    "modules = [Transformer,Estimator,param,Pipeline, evaluation]\n",
    "noms    = [\"Transformer\",\"Estimator\",\"param\",\"Pipeline\", \"evaluation\"]\n",
    "for nom, module in zip(noms, modules):\n",
    "    print(nom, [k for k in module.__dict__.keys() if \"_\" not in k])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transformer : Algorithme qui change une Dataframe en une autre (notamment en appliquant un modèle). Ce sont soit des modèles, soit des algorithmes d’ajouts de features\n",
    " * transform\n",
    "* Estimator : Objet pour créer un modèle sur une Dataframe\n",
    " * **fitMultiple**\n",
    " * **fit**\n",
    "* param : Paramètres des estimators et transformers. \n",
    " * **DenseVector**\n",
    " * **Vector** : Classe pour transformer les colonnes des DataFrame en vecteur *sparse*, c'est à dire que les valeurs nulles sont supprimées du vecteur. Seule reste les valeures entières associées à leur position dans le vecteur. C'est un moyen très efficace d'optimisation mémoire dans un contexte où les matrices sont souvent creuses.\n",
    " * **Matrix**\n",
    " * **Params** : Souvent des dictionnaire clefs : valeurs\n",
    " * **shared**\n",
    "* Pipeline : Permet d’organiser le chaînage d’Estimator et de  transformers\n",
    " * **stages**\n",
    " * **setStages**\n",
    " * **getStages**\n",
    " * **setParams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
